#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZVT_FOUR_FORCES_HUNTER.py - Zeta/4 For√ßas Fundamentais resonance hunter
Author: Jefferson M. Okushigue
Date: 2025-08-10
Modificado para buscar resson√¢ncias com as 4 for√ßas fundamentais
"""

import numpy as np
from mpmath import mp
import time
from concurrent.futures import ProcessPoolExecutor
import pickle
import os
import signal
import sys
from datetime import datetime
from scipy import stats
from scipy.stats import kstest, anderson
import warnings

warnings.filterwarnings("ignore", category=RuntimeWarning)

# Configuration
mp.dps = 50  # High precision

# 4 FOR√áAS FUNDAMENTAIS DA F√çSICA
FUNDAMENTAL_FORCES = {
    'eletromagnetica': 1 / 137.035999084,      # Œ± (constante de estrutura fina)
    'forte': 0.1185,                           # Œ±s (constante de acoplamento forte at MZ)
    'fraca': 0.0338,                           # Œ±W (constante de acoplamento fraca)
    'gravitacional': 5.906e-39                 # Œ±G (constante gravitacional adimensional)
}

# Toler√¢ncias espec√≠ficas para cada for√ßa (ajustadas √†s suas magnitudes)
FORCE_TOLERANCES = {
    'eletromagnetica': [1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9],
    'forte': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7],
    'fraca': [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8],
    'gravitacional': [1e-38, 1e-39, 1e-40, 1e-41, 1e-42, 1e-43]  # Toler√¢ncias apropriadas para escala gravitacional
}

# Constantes de controle para valida√ß√£o estat√≠stica
CONTROL_CONSTANTS = {
    'eletromagnetica': FUNDAMENTAL_FORCES['eletromagnetica'],
    'forte': FUNDAMENTAL_FORCES['forte'],
    'fraca': FUNDAMENTAL_FORCES['fraca'], 
    'random_1': 1 / 142.7,
    'random_2': 1 / 129.3,
    'golden_ratio': (np.sqrt(5) - 1) / 2,
    'pi_scale': np.pi / 100,
    'e_scale': np.e / 100
}

TOLERANCE_LEVELS = [1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9]
DEFAULT_TOLERANCE = 1e-5
INCREMENT = 10000  # Lotes maiores para processar mais rapidamente os 2M+ zeros

# CRIT√âRIOS PARA RESSON√ÇNCIA SIGNIFICATIVA
SIGNIFICANCE_CRITERIA = {
    'min_resonances': 10,           # M√≠nimo de resson√¢ncias
    'min_significance_factor': 2.0, # Fator de signific√¢ncia m√≠nimo (2x o esperado)
    'max_p_value': 0.01,           # p-value m√°ximo para signific√¢ncia
    'min_chi2_stat': 6.635         # œá¬≤ cr√≠tico para p < 0.01
}

MAX_WORKERS = os.cpu_count()
CACHE_FILE = "zeta_zeros_cache.pkl"
STATS_FILE = "zvt_4forces_stats.txt"
RESULTS_DIR = "zvt_4forces_results"
ZEROS_FILE = os.path.expanduser("~/zeta/zero.txt")  # Path to the zeros file

# Parameters for analysis
FRESH_START_ZEROS = 0  # 0 = usar todos os zeros dispon√≠veis
MINIMUM_FOR_STATS = 1000

# Create results directory if it doesn't exist
if not os.path.exists(RESULTS_DIR):
    os.makedirs(RESULTS_DIR)

# Global variable for shutdown control
shutdown_requested = False

# Signal handler for graceful shutdown
def signal_handler(signum, frame):
    global shutdown_requested
    print(f"\n‚è∏Ô∏è Shutdown solicitado. Completando lote atual e salvando...")
    shutdown_requested = True

# Fun√ß√£o para verificar se uma resson√¢ncia √© significativa
def is_significant_resonance(resonances, stats_result, force_name, constant_value, tolerance):
    """Verifica se uma resson√¢ncia atende aos crit√©rios de signific√¢ncia"""
    if not stats_result or len(resonances) < SIGNIFICANCE_CRITERIA['min_resonances']:
        return False, "Insuficientes resson√¢ncias"
    
    basic_stats = stats_result['basic_stats']
    significance_factor = basic_stats['significance_factor']
    
    # Verificar fator de signific√¢ncia
    if significance_factor < SIGNIFICANCE_CRITERIA['min_significance_factor']:
        return False, f"Signific√¢ncia baixa: {significance_factor:.2f}x"
    
    # Verificar testes estat√≠sticos
    significant_tests = []
    
    if 'chi2_test' in stats_result:
        chi2 = stats_result['chi2_test']
        if chi2['statistic'] > SIGNIFICANCE_CRITERIA['min_chi2_stat']:
            significant_tests.append(f"Chi2: œá¬≤={chi2['statistic']:.3f}")
    
    if 'binomial_test' in stats_result:
        binom = stats_result['binomial_test']
        if binom['p_value'] < SIGNIFICANCE_CRITERIA['max_p_value']:
            significant_tests.append(f"Binomial: p={binom['p_value']:.2e}")
    
    if 'poisson_test' in stats_result:
        poisson = stats_result['poisson_test']
        if poisson['p_value'] < SIGNIFICANCE_CRITERIA['max_p_value']:
            significant_tests.append(f"Poisson: p={poisson['p_value']:.2e}")
    
    if len(significant_tests) > 0:
        return True, f"Testes significativos: {', '.join(significant_tests)}"
    
    return False, "Nenhum teste estat√≠stico significativo"

# Fun√ß√£o para log de resson√¢ncia significativa (sem pausa)
def log_significant_resonance(force_name, constant_value, tolerance, resonances, stats_result, zeros_count):
    """Registra resson√¢ncia significativa no log sem pausar"""
    print("\n" + "üö®" * 40)
    print("üö® RESSON√ÇNCIA SIGNIFICATIVA DETECTADA! üö®")
    print("üö®" * 40)
    print(f"üî¨ FOR√áA: {force_name.upper()}")
    print(f"üéØ CONSTANTE: {constant_value:.15e}")
    print(f"üìè TOLER√ÇNCIA: {tolerance:.0e}")
    print(f"üìä ZEROS ANALISADOS: {zeros_count:,}")
    print(f"üîç RESSON√ÇNCIAS: {len(resonances):,}")
    
    if stats_result:
        basic = stats_result['basic_stats']
        print(f"üìà Taxa: {basic['resonance_rate']*100:.6f}% | Signific√¢ncia: {basic['significance_factor']:.3f}x")
        
        if 'chi2_test' in stats_result:
            chi2 = stats_result['chi2_test']
            print(f"üß™ œá¬≤={chi2['statistic']:.3f}, p={chi2['p_value']:.2e}")
    
    # Mostrar as 5 melhores resson√¢ncias
    if resonances:
        best_resonances = sorted(resonances, key=lambda x: x[2])[:5]
        print(f"\nüíé TOP 5 MELHORES RESSON√ÇNCIAS:")
        print("| Rank | Zero #    | Gamma            | Qualidade        | Energia (GeV) |")
        print("|------|-----------|------------------|------------------|---------------|")
        for i, (n, gamma, quality, _) in enumerate(best_resonances, 1):
            energy = gamma / 10  # Estimativa de energia
            print(f"| {i:4d} | {n:9,} | {gamma:16.12f} | {quality:.6e} | {energy:13.3f} |")
    
    print("üö®" * 40)
    print("‚ñ∂Ô∏è CONTINUANDO AN√ÅLISE AUTOMATICAMENTE...\n")

# Load zeros from a file with progress indicator
def load_zeros_from_file(filename):
    zeros = []
    try:
        print(f"üìÇ Carregando zeros do arquivo: {filename}")
        
        # Primeiro, contar total de linhas para mostrar progresso
        print("üìä Contando linhas do arquivo...")
        with open(filename, 'r') as f:
            total_lines = sum(1 for line in f if line.strip())
        print(f"üìä Total de linhas encontradas: {total_lines:,}")
        
        with open(filename, 'r') as f:
            progress_counter = 0
            for line_num, line in enumerate(f, start=1):
                if shutdown_requested:
                    break
                line = line.strip()
                if line:
                    try:
                        zero = float(line)
                        zeros.append((line_num, zero))  # Format: (index, value)
                        progress_counter += 1
                        
                        # Mostrar progresso a cada 100,000 zeros
                        if progress_counter % 100000 == 0:
                            percent = (progress_counter / total_lines) * 100
                            print(f"üìà Carregados {progress_counter:,} zeros ({percent:.1f}%)")
                            
                    except ValueError:
                        print(f"‚ö†Ô∏è Linha inv√°lida {line_num}: '{line}'")
                        continue
        print(f"‚úÖ {len(zeros):,} zeros carregados com sucesso de {total_lines:,} linhas")
        return zeros
    except Exception as e:
        print(f"‚ùå Erro ao ler arquivo: {e}")
        return []

# Save zeros to cache
def save_enhanced_cache(zeros, backup=True):
    try:
        if backup and os.path.exists(CACHE_FILE):
            backup_file = f"{CACHE_FILE}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            os.rename(CACHE_FILE, backup_file)
            print(f"üì¶ Backup do cache criado: {backup_file}")
        with open(CACHE_FILE, 'wb') as f:
            pickle.dump(zeros, f, protocol=pickle.HIGHEST_PROTOCOL)
        print(f"üíæ Cache salvo: {len(zeros)} zeros")
    except Exception as e:
        print(f"‚ùå Erro ao salvar cache: {e}")

# Load zeros from cache or file with forced reload option
def load_enhanced_cache(force_reload=False):
    if not force_reload and os.path.exists(CACHE_FILE):
        try:
            print(f"üîç Verificando cache existente...")
            with open(CACHE_FILE, 'rb') as f:
                data = pickle.load(f)
                if isinstance(data, list) and len(data) > 0:
                    print(f"‚úÖ Cache v√°lido: {len(data):,} zeros carregados")
                    
                    # Verificar se o cache parece completo
                    file_size = os.path.getsize(ZEROS_FILE)
                    expected_zeros = file_size // 20  # Estimativa aproximada (20 bytes por zero)
                    
                    if len(data) < expected_zeros * 0.5:  # Se cache tem menos de 50% do esperado
                        print(f"‚ö†Ô∏è Cache parece incompleto ({len(data):,} vs ~{expected_zeros:,} esperados)")
                        print(f"üîÑ For√ßando recarga do arquivo...")
                        force_reload = True
                    else:
                        return data
        except Exception as e:
            print(f"‚ö†Ô∏è Cache inv√°lido ({e}), carregando do arquivo...")
            force_reload = True
    
    if force_reload or not os.path.exists(CACHE_FILE):
        print("üìÇ Carregando todos os zeros do arquivo original...")
        zeros = load_zeros_from_file(ZEROS_FILE)
        if zeros:
            print(f"üíæ Salvando {len(zeros):,} zeros no cache...")
            save_enhanced_cache(zeros)
            return zeros
    return []

# Find resonances at multiple tolerance levels with force-specific tolerances
def find_multi_tolerance_resonances(zeros, constants_dict=None):
    if constants_dict is None:
        constants_dict = FUNDAMENTAL_FORCES
    all_results = {}
    for const_name, const_value in constants_dict.items():
        all_results[const_name] = {}
        
        # Usar toler√¢ncias espec√≠ficas para cada for√ßa ou toler√¢ncias gen√©ricas para outras constantes
        if const_name in FORCE_TOLERANCES:
            tolerances_to_use = FORCE_TOLERANCES[const_name]
        else:
            tolerances_to_use = TOLERANCE_LEVELS
            
        for tolerance in tolerances_to_use:
            resonances = []
            for n, gamma in zeros:
                mod_val = gamma % const_value
                min_distance = min(mod_val, const_value - mod_val)
                if min_distance < tolerance:
                    resonances.append((n, gamma, min_distance, tolerance))
            all_results[const_name][tolerance] = resonances
    return all_results

# Enhanced statistical analysis with validation
def enhanced_statistical_analysis(zeros, resonances, constant_value, tolerance):
    if len(zeros) == 0 or len(resonances) == 0:
        return None
    total_zeros = len(zeros)
    resonant_count = len(resonances)
    expected_random = total_zeros * (2 * tolerance / constant_value)
    
    # Valida√ß√£o b√°sica para evitar valores inv√°lidos
    if constant_value <= 0 or tolerance <= 0:
        return None
        
    results = {
        'basic_stats': {
            'total_zeros': total_zeros,
            'resonant_count': resonant_count,
            'expected_random': expected_random,
            'resonance_rate': resonant_count / total_zeros,
            'significance_factor': resonant_count / expected_random if expected_random > 0 else float('inf')
        }
    }
    
    # Teste qui-quadrado (apenas se esperado >= 5)
    if expected_random >= 5:
        chi2_stat = (resonant_count - expected_random)**2 / expected_random
        chi2_pvalue = 1 - stats.chi2.cdf(chi2_stat, df=1)
        results['chi2_test'] = {
            'statistic': chi2_stat,
            'p_value': chi2_pvalue,
            'critical_value_05': 3.841,
            'significant': chi2_stat > 3.841
        }
    
    # Teste binomial com valida√ß√£o de probabilidade
    p_expected = 2 * tolerance / constant_value
    
    # Verificar se p_expected est√° no intervalo v√°lido [0,1]
    if 0 <= p_expected <= 1:
        try:
            binom_result = stats.binomtest(resonant_count, total_zeros, p_expected, alternative='two-sided')
            binom_pvalue = binom_result.pvalue
        except AttributeError:
            try:
                binom_pvalue = stats.binom_test(resonant_count, total_zeros, p_expected, alternative='two-sided')
            except AttributeError:
                from scipy.stats import binom
                binom_pvalue = 2 * min(binom.cdf(resonant_count, total_zeros, p_expected),
                                      1 - binom.cdf(resonant_count - 1, total_zeros, p_expected))
        except Exception as e:
            print(f"    Aviso: Teste binomial falhou: {e}")
            binom_pvalue = 1.0  # p-value neutro em caso de erro
            
        results['binomial_test'] = {
            'p_value': binom_pvalue,
            'significant': binom_pvalue < 0.05
        }
    else:
        # Se p_expected √© inv√°lido, n√£o fazer teste binomial
        print(f"    Aviso: p_expected={p_expected:.2e} fora do intervalo [0,1] - pulando teste binomial")
        results['binomial_test'] = {
            'p_value': 1.0,  # p-value neutro
            'significant': False,
            'invalid_probability': True
        }
    
    # Teste de Poisson (mais robusto para casos extremos)
    if expected_random > 0:
        try:
            poisson_pvalue = 1 - stats.poisson.cdf(resonant_count - 1, expected_random)
            results['poisson_test'] = {
                'p_value': poisson_pvalue,
                'significant': poisson_pvalue < 0.05
            }
        except Exception as e:
            print(f"    Aviso: Teste de Poisson falhou: {e}")
            results['poisson_test'] = {
                'p_value': 1.0,
                'significant': False
            }
    
    return results

# Compare resonances between different constants
def comparative_constant_analysis(zeros, tolerance=DEFAULT_TOLERANCE):
    multi_results = find_multi_tolerance_resonances(zeros, CONTROL_CONSTANTS)
    comparative_stats = {}
    for const_name, const_results in multi_results.items():
        if tolerance in const_results:
            resonances = const_results[tolerance]
            const_value = CONTROL_CONSTANTS[const_name]
            stats_result = enhanced_statistical_analysis(zeros, resonances, const_value, tolerance)
            comparative_stats[const_name] = {
                'constant_value': const_value,
                'resonance_count': len(resonances),
                'resonance_rate': len(resonances) / len(zeros) * 100,
                'stats': stats_result
            }
    return comparative_stats

# Analyze a batch of zeros with significance detection (sem pausa)
def analyze_batch_with_significance_detection(zeros, batch_num):
    print(f"\nüî¨ LOTE #{batch_num}: {len(zeros):,} zeros")
    
    # An√°lise das 4 for√ßas fundamentais
    forces_results = find_multi_tolerance_resonances(zeros, FUNDAMENTAL_FORCES)
    
    significant_found = False
    best_resonances = {}  # Armazenar melhores resson√¢ncias por for√ßa
    
    print(f"\nüåå AN√ÅLISE DAS 4 FOR√áAS FUNDAMENTAIS:")
    print("| For√ßa         | Constante    | Toler√¢ncia | Resson√¢ncias | Taxa (%) | Signific√¢ncia |")
    print("|---------------|--------------|------------|--------------|----------|---------------|")
    
    for force_name, force_value in FUNDAMENTAL_FORCES.items():
        # Usar toler√¢ncias espec√≠ficas para cada for√ßa
        tolerances_to_check = FORCE_TOLERANCES.get(force_name, TOLERANCE_LEVELS[:3])
        
        for tolerance in tolerances_to_check[:3]:  # Verificar apenas as 3 principais toler√¢ncias de cada for√ßa
            try:
                if tolerance in forces_results[force_name]:
                    resonances = forces_results[force_name][tolerance]
                    count = len(resonances)
                    rate = count / len(zeros) * 100 if len(zeros) > 0 else 0
                    
                    stats_result = enhanced_statistical_analysis(zeros, resonances, force_value, tolerance)
                    sig_factor = stats_result['basic_stats']['significance_factor'] if stats_result else 0
                    
                    # Mostrar status de signific√¢ncia na tabela
                    sig_marker = "üö®" if sig_factor > SIGNIFICANCE_CRITERIA['min_significance_factor'] else "  "
                    print(f"|{sig_marker}{force_name:11s} | {force_value:.12e} | {tolerance:8.0e} | {count:10d} | {rate:8.3f} | {sig_factor:8.2f}x |")
                    
                    # Guardar melhor resson√¢ncia para cada for√ßa
                    if resonances:
                        current_best = min(resonances, key=lambda x: x[2])
                        if force_name not in best_resonances or current_best[2] < best_resonances[force_name][2]:
                            best_resonances[force_name] = current_best
                    
                    # Verificar se √© significativo e registrar no log
                    is_sig, reason = is_significant_resonance(resonances, stats_result, force_name, force_value, tolerance)
                    if is_sig:
                        significant_found = True
                        log_significant_resonance(force_name, force_value, tolerance, resonances, stats_result, len(zeros))
                else:
                    print(f"|  {force_name:11s} | {force_value:.12e} | {tolerance:8.0e} |        N/A |      N/A |      N/A |")
            except Exception as e:
                print(f"|‚ùå{force_name:11s} | {force_value:.12e} | {tolerance:8.0e} |      ERRO |      N/A |      N/A |")
                print(f"    Erro na an√°lise de {force_name}: {e}")
                continue
    
    # Mostrar melhores resson√¢ncias encontradas para cada for√ßa
    if best_resonances:
        print(f"\nüíé MELHORES RESSON√ÇNCIAS ENCONTRADAS:")
        print("| For√ßa         | Zero #    | Gamma            | Qualidade      | Energia (GeV) |")
        print("|---------------|-----------|------------------|----------------|---------------|")
        for force_name, (n, gamma, quality, tolerance) in best_resonances.items():
            energy = gamma / 10  # Estimativa de energia
            print(f"| {force_name:13s} | {n:9,} | {gamma:16.12f} | {quality:.6e} | {energy:13.3f} |")
    
    # An√°lise comparativa sempre continua (com tratamento de erro)
    try:
        comparative_analysis = comparative_constant_analysis(zeros)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro na an√°lise comparativa: {e}")
        comparative_analysis = {}
    
    return forces_results, comparative_analysis, best_resonances, 'continue'

# Generate a comprehensive report
def generate_comprehensive_report(zeros, session_results, final_batch):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = os.path.join(RESULTS_DIR, f"Relatorio_4Forcas_{timestamp}.txt")
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("ZVT 4 FOR√áAS FUNDAMENTAIS HUNTER - RELAT√ìRIO COMPREENSIVO\n")
        f.write("="*80 + "\n\n")
        f.write(f"Data: {datetime.now().isoformat()}\n")
        f.write(f"Vers√£o: Four Forces Hunter v1.0\n")
        f.write(f"Lote Final: #{final_batch}\n")
        f.write(f"Zeros Analisados: {len(zeros):,}\n")
        f.write(f"Arquivo de Origem: {ZEROS_FILE}\n\n")
        
        f.write("CONFIGURA√á√ÉO DAS 4 FOR√áAS FUNDAMENTAIS:\n")
        for force_name, force_value in FUNDAMENTAL_FORCES.items():
            tolerances_str = ", ".join([f"{t:.0e}" for t in FORCE_TOLERANCES.get(force_name, TOLERANCE_LEVELS)])
            f.write(f"  {force_name.capitalize()}: {force_value:.15e} (toler√¢ncias: {tolerances_str})\n")
        
        f.write(f"\nPrecis√£o: {mp.dps} casas decimais\n\n")
        
        f.write("CRIT√âRIOS DE SIGNIFIC√ÇNCIA:\n")
        for key, value in SIGNIFICANCE_CRITERIA.items():
            f.write(f"  {key}: {value}\n")
        
        f.write("\n" + "="*80 + "\n")
    
    print(f"üìä Relat√≥rio salvo: {report_file}")
    return report_file

# Main function
def infinite_hunter_four_forces():
    global shutdown_requested
    print(f"üöÄ ZVT 4 FOR√áAS FUNDAMENTAIS HUNTER")
    print(f"üåå Buscando resson√¢ncias com as 4 for√ßas fundamentais da f√≠sica")
    print("=" * 80)
    
    for force_name, force_value in FUNDAMENTAL_FORCES.items():
        tolerances_str = ", ".join([f"{t:.0e}" for t in FORCE_TOLERANCES.get(force_name, TOLERANCE_LEVELS)[:3]])
        print(f"üî¨ {force_name.upper()}: {force_value:.15e} (toler√¢ncias: {tolerances_str})")
    
    print(f"\nüìÅ Arquivo: {ZEROS_FILE}")
    print("üõë Ctrl+C para parar")
    print("üö® Resson√¢ncias significativas ser√£o destacadas automaticamente")
    print("=" * 80)
    
    # Verificar se deve for√ßar recarga
    force_reload = False
    if len(sys.argv) > 1 and sys.argv[1] == '--force-reload':
        force_reload = True
        print("üîÑ MODO FOR√áA RECARGA ATIVADO - Recarregando do arquivo original")
    
    all_zeros = load_enhanced_cache(force_reload=force_reload)
    current_count = len(all_zeros)
    
    if current_count == 0:
        print("‚ùå Nenhum zero carregado. Verifique o arquivo.")
        return [], [], None
    
    if current_count == 0:
        print("‚ùå Nenhum zero carregado. Verifique o arquivo.")
        return [], [], None
    
    # Diagn√≥stico do arquivo original
    try:
        file_size = os.path.getsize(ZEROS_FILE)
        print(f"üìä Arquivo original: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)")
        with open(ZEROS_FILE, 'r') as f:
            total_lines = sum(1 for line in f if line.strip())
        print(f"üìä Linhas no arquivo: {total_lines:,}")
        print(f"üìä Zeros carregados: {current_count:,}")
        
        if current_count < total_lines * 0.9:  # Se carregou menos de 90% das linhas
            print(f"‚ö†Ô∏è AVISO: Carregou apenas {(current_count/total_lines)*100:.1f}% do arquivo!")
            print(f"üí° Execute com: python3 {sys.argv[0]} --force-reload")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao verificar arquivo: {e}")
    
    print(f"üéØ PROCESSANDO TODOS OS {current_count:,} ZEROS!")
    print(f"üì¶ Lotes de {INCREMENT:,} zeros cada")
    print(f"‚è±Ô∏è Estimativa: ~{(current_count//INCREMENT)} lotes")
    
    session_results = []
    best_overall = {}  # Melhores resson√¢ncias globais por for√ßa
    batch_num = 1
    
    for i in range(0, current_count, INCREMENT):
        if shutdown_requested:
            break
        
        batch_start = i
        batch_end = min(i + INCREMENT, current_count)
        batch = all_zeros[batch_start:batch_end]
        
        # Indicador de progresso
        progress_percent = (batch_end / current_count) * 100
        print(f"\nüî¨ LOTE #{batch_num}: Zeros {batch_start:,} a {batch_end:,} ({progress_percent:.1f}% conclu√≠do)")
        start_time = time.time()
        
        forces_analysis, comparative_analysis, batch_best, decision = analyze_batch_with_significance_detection(batch, batch_num)
        
        # Atualizar melhores resson√¢ncias globais
        if batch_best:
            for force_name, (n, gamma, quality, tolerance) in batch_best.items():
                if force_name not in best_overall or quality < best_overall[force_name][2]:
                    best_overall[force_name] = (n, gamma, quality, tolerance)
                    print(f"    üéØ NOVO MELHOR GLOBAL para {force_name.upper()}!")
                    print(f"    Zero #{n:,} ‚Üí Œ≥={gamma:.12f}, qualidade={quality:.6e}")
        
        elapsed = time.time() - start_time
        zeros_per_sec = len(batch) / elapsed if elapsed > 0 else 0
        remaining_zeros = current_count - batch_end
        eta_seconds = remaining_zeros / zeros_per_sec if zeros_per_sec > 0 else 0
        eta_hours = eta_seconds / 3600
        
        print(f"‚è±Ô∏è Lote processado em {elapsed:.1f}s ({zeros_per_sec:,.0f} zeros/s)")
        if eta_hours > 0:
            print(f"üìà ETA para conclus√£o: {eta_hours:.1f} horas")
        
        session_results.append({
            'batch': batch_num,
            'timestamp': datetime.now().isoformat(),
            'zeros_analyzed': batch_end,
            'batch_time': elapsed,
            'forces_analysis': forces_analysis,
            'comparative_analysis': comparative_analysis,
            'best_resonance': batch_best,
            'progress_percent': progress_percent
        })
        
        batch_num += 1
    
    print(f"\nüìä Gerando relat√≥rio final...")
    generate_comprehensive_report(all_zeros, session_results, batch_num-1)
    
    # Mostrar melhores resson√¢ncias globais
    if best_overall:
        print(f"\n" + "üèÜ" * 60)
        print(f"üèÜ MELHORES RESSON√ÇNCIAS GLOBAIS ENCONTRADAS üèÜ")
        print(f"üèÜ" * 60)
        print("| For√ßa         | Zero #        | Gamma                | Qualidade        | Energia (GeV) |")
        print("|---------------|---------------|----------------------|------------------|---------------|")
        for force_name, (n, gamma, quality, tolerance) in best_overall.items():
            energy = gamma / 10
            print(f"| {force_name:13s} | {n:13,} | {gamma:20.15f} | {quality:.6e} | {energy:13.6f} |")
        
        print(f"\nüíé DETALHES DAS MELHORES RESSON√ÇNCIAS:")
        for force_name, (n, gamma, quality, tolerance) in best_overall.items():
            error_percent = (quality / FUNDAMENTAL_FORCES[force_name]) * 100
            print(f"\nüî¨ {force_name.upper()}:")
            print(f"   Zero #{n:,} (Œ≥ = {gamma:.15f})")
            print(f"   Qualidade: {quality:.15e}")
            print(f"   Erro relativo: {error_percent:.12f}%")
            print(f"   Toler√¢ncia: {tolerance:.0e}")
            print(f"   Energia estimada: {gamma/10:.6f} GeV")
        print(f"üèÜ" * 60)
    
    # Resumo final
    total_processed = session_results[-1]['zeros_analyzed'] if session_results else 0
    print(f"\n" + "="*60)
    print(f"üìä RESUMO FINAL DA AN√ÅLISE")
    print(f"="*60)
    print(f"üìà Total de zeros processados: {total_processed:,} de {current_count:,}")
    print(f"üìà Porcentagem conclu√≠da: {(total_processed/current_count)*100:.1f}%")
    print(f"üìà Lotes processados: {len(session_results)}")
    if session_results:
        total_time = sum(r['batch_time'] for r in session_results)
        avg_time = total_time / len(session_results)
        print(f"üìà Tempo total: {total_time:.1f}s ({total_time/3600:.1f}h)")
        print(f"üìà Tempo m√©dio por lote: {avg_time:.1f}s")
        print(f"üìà Velocidade m√©dia: {total_processed/total_time:,.0f} zeros/s")
    print(f"="*60)
    
    return all_zeros, session_results, best_overall

# Main execution
if __name__ == "__main__":
    shutdown_requested = False
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        print("üåü Iniciando ZVT 4 For√ßas Fundamentais Hunter")
        zeros, results, best = infinite_hunter_four_forces()
        
        if zeros and len(zeros) > 0:
            print(f"\nüéØ An√°lise Conclu√≠da!")
            print(f"üìÅ Resultados em: {RESULTS_DIR}/")
            print(f"üíæ Cache: {CACHE_FILE}")
            print(f"üìä Estat√≠sticas: {STATS_FILE}")
    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è An√°lise interrompida. Progresso salvo.")
    except Exception as e:
        print(f"\n‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print(f"\nüî¨ Sess√£o conclu√≠da!")
