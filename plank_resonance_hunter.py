#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZVT_PLANCK_RESONANCE_HUNTER.py - Zeta/Planck resonance hunter with file loading
Author: Jefferson M. Okushigue
Date: 2025-08-09
"""

import numpy as np
from mpmath import mp
import time
from concurrent.futures import ProcessPoolExecutor
import pickle
import os
import signal
import sys
from datetime import datetime
from scipy import stats
from scipy.stats import kstest, anderson
import warnings
import math

warnings.filterwarnings("ignore", category=RuntimeWarning)

# Configuration
mp.dps = 50  # High precision

# Constantes de Planck e quantidades derivadas
H_PLANCK = 6.62607015e-34  # J¬∑s (valor exato CODATA 2018)
H_BAR = H_PLANCK / (2 * math.pi)  # ‚Ñè = h/(2œÄ)
C_LIGHT = 299792458  # m/s
G_GRAVITY = 6.67430e-11  # m¬≥‚ãÖkg‚Åª¬π‚ãÖs‚Åª¬≤

# Unidades de Planck fundamentais
L_PLANCK = math.sqrt(H_BAR * G_GRAVITY / C_LIGHT**3)  # 1.616e-35 m
T_PLANCK = L_PLANCK / C_LIGHT  # 5.391e-44 s
M_PLANCK = math.sqrt(H_BAR * C_LIGHT / G_GRAVITY)  # 2.176e-8 kg
E_PLANCK = M_PLANCK * C_LIGHT**2  # 1.956e9 J
F_PLANCK = 1 / T_PLANCK  # 1.855e43 Hz

# Constantes principais para an√°lise - m√∫ltiplos para compatibilidade com zeros
PLANCK_CONSTANT = H_PLANCK
PLANCK_REDUCED = H_BAR

# M√∫ltiplos da constante de Planck para busca
PLANCK_MULTIPLIERS = [
    1e30 * H_PLANCK,   # 6.626e-4
    1e32 * H_PLANCK,   # 6.626e-2  
    1e34 * H_PLANCK,   # 6.626
    1e35 * H_PLANCK,   # 66.26
    1e36 * H_PLANCK,   # 662.6
    1e37 * H_PLANCK,   # 6626
]

TOLERANCE_LEVELS = [1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11]  # Toler√¢ncias relativas
DEFAULT_TOLERANCE = 1e-8
INCREMENT = 1000  # Batch size for processing

# Constantes de controle para valida√ß√£o estat√≠stica
CONTROL_CONSTANTS = {
    'planck_30x': 1e30 * H_PLANCK,  # 6.626e-4
    'planck_32x': 1e32 * H_PLANCK,  # 6.626e-2
    'planck_34x': 1e34 * H_PLANCK,  # 6.626
    'planck_35x': 1e35 * H_PLANCK,  # 66.26
    'planck_36x': 1e36 * H_PLANCK,  # 662.6
    'planck_37x': 1e37 * H_PLANCK,  # 6626
    'planck_hbar_34x': 1e34 * H_BAR,  # 1.055
    'random_1': 6.5,
    'random_2': 6.8,
    'random_3': 1.0,
    'random_4': 66.5,
}

MAX_WORKERS = os.cpu_count()
CACHE_FILE = "zeta_zeros_cache.pkl"
STATS_FILE = "zvt_planck_stats.txt"
RESULTS_DIR = "zvt_planck_results"
ZEROS_FILE = os.path.expanduser("~/Downloads/zero.txt")  # Path to the zeros file

# Parameters for analysis
FRESH_START_ZEROS = 5000
MINIMUM_FOR_STATS = 1000

# Create results directory if it doesn't exist
if not os.path.exists(RESULTS_DIR):
    os.makedirs(RESULTS_DIR)

# Global variable for shutdown control
shutdown_requested = False

def signal_handler(signum, frame):
    global shutdown_requested
    print(f"\n‚è∏Ô∏è Shutdown solicitado. Completando lote atual e salvando...")
    shutdown_requested = True

def load_zeros_from_file(filename):
    zeros = []
    try:
        print(f"üìÇ Carregando zeros do arquivo: {filename}")
        with open(filename, 'r') as f:
            for line_num, line in enumerate(f, start=1):
                if shutdown_requested:
                    break
                line = line.strip()
                if line:
                    try:
                        zero = float(line)
                        zeros.append((line_num, zero))  # Format: (index, value)
                    except ValueError:
                        print(f"‚ö†Ô∏è Linha inv√°lida {line_num}: '{line}'")
                        continue
        print(f"‚úÖ {len(zeros):,} zeros carregados")
        return zeros
    except Exception as e:
        print(f"‚ùå Erro ao ler arquivo: {e}")
        return []

def save_enhanced_cache(zeros, backup=True):
    try:
        if backup and os.path.exists(CACHE_FILE):
            backup_file = f"{CACHE_FILE}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            os.rename(CACHE_FILE, backup_file)
            print(f"üì¶ Backup do cache criado: {backup_file}")
        with open(CACHE_FILE, 'wb') as f:
            pickle.dump(zeros, f, protocol=pickle.HIGHEST_PROTOCOL)
        print(f"üíæ Cache salvo: {len(zeros)} zeros")
    except Exception as e:
        print(f"‚ùå Erro ao salvar cache: {e}")

def load_enhanced_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'rb') as f:
                data = pickle.load(f)
                if isinstance(data, list) and len(data) > 0:
                    print(f"‚úÖ Cache v√°lido: {len(data):,} zeros carregados")
                    return data
        except:
            print("‚ö†Ô∏è Cache inv√°lido, carregando do arquivo...")
    zeros = load_zeros_from_file(ZEROS_FILE)
    if zeros:
        save_enhanced_cache(zeros)
        return zeros[:FRESH_START_ZEROS] if FRESH_START_ZEROS > 0 else zeros
    return []

def find_multi_tolerance_resonances(zeros, constants_dict=None):
    if constants_dict is None:
        constants_dict = {'planck_34x': 1e34 * PLANCK_CONSTANT}
    all_results = {}
    for const_name, const_value in constants_dict.items():
        all_results[const_name] = {}
        for tolerance in TOLERANCE_LEVELS:
            resonances = []
            for n, gamma in zeros:
                mod_val = gamma % const_value
                min_distance = min(mod_val, const_value - mod_val)
                relative_error = min_distance / const_value  # Erro relativo
                if relative_error < tolerance:
                    resonances.append((n, gamma, min_distance, tolerance, relative_error))
            all_results[const_name][tolerance] = resonances
    return all_results

def enhanced_statistical_analysis(zeros, resonances, constant_value, tolerance):
    if len(zeros) == 0 or len(resonances) == 0:
        return None
    total_zeros = len(zeros)
    resonant_count = len(resonances)
    expected_random = total_zeros * (2 * tolerance)  # Agora tolerance √© relativo
    results = {
        'basic_stats': {
            'total_zeros': total_zeros,
            'resonant_count': resonant_count,
            'expected_random': expected_random,
            'resonance_rate': resonant_count / total_zeros,
            'significance_factor': resonant_count / expected_random if expected_random > 0 else float('inf')
        }
    }
    if expected_random >= 5:
        chi2_stat = (resonant_count - expected_random)**2 / expected_random
        chi2_pvalue = 1 - stats.chi2.cdf(chi2_stat, df=1)
        results['chi2_test'] = {
            'statistic': chi2_stat,
            'p_value': chi2_pvalue,
            'critical_value_05': 3.841,
            'significant': chi2_stat > 3.841
        }
    p_expected = 2 * tolerance  # Toler√¢ncia j√° √© relativa
    try:
        binom_result = stats.binomtest(resonant_count, total_zeros, p_expected, alternative='two-sided')
        binom_pvalue = binom_result.pvalue
    except AttributeError:
        try:
            binom_pvalue = stats.binom_test(resonant_count, total_zeros, p_expected, alternative='two-sided')
        except AttributeError:
            from scipy.stats import binom
            binom_pvalue = 2 * min(binom.cdf(resonant_count, total_zeros, p_expected),
                                  1 - binom.cdf(resonant_count - 1, total_zeros, p_expected))
    results['binomial_test'] = {
        'p_value': binom_pvalue,
        'significant': binom_pvalue < 0.05
    }
    poisson_pvalue = 1 - stats.poisson.cdf(resonant_count - 1, expected_random)
    results['poisson_test'] = {
        'p_value': poisson_pvalue,
        'significant': poisson_pvalue < 0.05
    }
    return results

def comparative_constant_analysis(zeros, tolerance=DEFAULT_TOLERANCE):
    multi_results = find_multi_tolerance_resonances(zeros, CONTROL_CONSTANTS)
    comparative_stats = {}
    for const_name, const_results in multi_results.items():
        if tolerance in const_results:
            resonances = const_results[tolerance]
            const_value = CONTROL_CONSTANTS[const_name]
            stats_result = enhanced_statistical_analysis(zeros, resonances, const_value, tolerance)
            comparative_stats[const_name] = {
                'constant_value': const_value,
                'resonance_count': len(resonances),
                'resonance_rate': len(resonances) / len(zeros) * 100,
                'stats': stats_result
            }
    return comparative_stats

def analyze_batch_enhanced(zeros, batch_num):
    print(f"\nüî¨ LOTE #{batch_num}: {len(zeros):,} zeros")
    if len(zeros) < MINIMUM_FOR_STATS:
        print(f"   üìä Necess√°rio {MINIMUM_FOR_STATS - len(zeros):,} mais zeros para estat√≠sticas")
        planck_results = find_multi_tolerance_resonances(zeros, {'planck_34x': 1e34 * PLANCK_CONSTANT})['planck_34x']
        tolerance_summary = {}
        for tolerance in TOLERANCE_LEVELS[:3]:
            if tolerance in planck_results:
                resonances = planck_results[tolerance]
                count = len(resonances)
                rate = count / len(zeros) * 100 if len(zeros) > 0 else 0
                tolerance_summary[tolerance] = {
                    'count': count,
                    'rate': rate,
                    'best_quality': min(r[4] for r in resonances) if count > 0 else None,  # Erro relativo
                    'resonances': resonances,
                    'stats': None
                }
        print(f"\nüìä RESSON√ÇNCIAS B√ÅSICAS (PLANCK 10¬≥‚Å¥√óh):")
        print("| Toler√¢ncia | Contagem | Taxa (%) |")
        print("|------------|----------|----------|")
        for tolerance in TOLERANCE_LEVELS[:3]:
            if tolerance in tolerance_summary:
                data = tolerance_summary[tolerance]
                print(f"| {tolerance:8.0e} | {data['count']:8d} | {data['rate']:8.3f} |")
        return tolerance_summary, {}, None
    
    planck_results = find_multi_tolerance_resonances(zeros, {'planck_34x': 1e34 * PLANCK_CONSTANT})['planck_34x']
    print(f"\nüìä RESSON√ÇNCIAS PLANCK POR TOLER√ÇNCIA (10¬≥‚Å¥√óh = {1e34 * PLANCK_CONSTANT:.3f}):")
    print("| Toler√¢ncia | Contagem | Taxa (%) | Melhor Qualidade | Signific√¢ncia |")
    print("|------------|----------|----------|------------------|---------------|")
    tolerance_summary = {}
    for tolerance in TOLERANCE_LEVELS:
        if tolerance in planck_results:
            resonances = planck_results[tolerance]
            count = len(resonances)
            rate = count / len(zeros) * 100
            if count > 0:
                best_quality = min(r[4] for r in resonances)  # Erro relativo
                stats_result = enhanced_statistical_analysis(zeros, resonances, 1e34 * PLANCK_CONSTANT, tolerance)
                sig_factor = stats_result['basic_stats']['significance_factor'] if stats_result else 0
                tolerance_summary[tolerance] = {
                    'count': count,
                    'rate': rate,
                    'best_quality': best_quality,
                    'significance': sig_factor,
                    'resonances': resonances,
                    'stats': stats_result
                }
                print(f"| {tolerance:8.0e} | {count:8d} | {rate:8.3f} | {best_quality:.3e} | {sig_factor:8.2f}x |")
            else:
                tolerance_summary[tolerance] = {
                    'count': 0, 'rate': 0, 'best_quality': None,
                    'significance': 0, 'resonances': [], 'stats': None
                }
                print(f"| {tolerance:8.0e} | {count:8d} | {rate:8.3f} |      N/A     |     N/A    |")
    
    print(f"\nüéõÔ∏è COMPARA√á√ÉO DE CONSTANTES PLANCK (Toler√¢ncia: {DEFAULT_TOLERANCE}):")
    comparative_results = comparative_constant_analysis(zeros, DEFAULT_TOLERANCE)
    print("| Constante     | Valor          | Contagem | Taxa (%) | Signific√¢ncia |")
    print("|---------------|----------------|----------|----------|---------------|")
    for const_name, results in comparative_results.items():
        count = results['resonance_count']
        rate = results['resonance_rate']
        sig_factor = results['stats']['basic_stats']['significance_factor'] if results['stats'] else 0
        value = results['constant_value']
        if value > 1e-30:
            value_str = f"{value:.3e}"
        else:
            value_str = f"{value:.3e}"
        print(f"| {const_name:13s} | {value_str:14s} | {count:8d} | {rate:8.3f} | {sig_factor:8.2f}x |")
    
    best_overall = None
    if DEFAULT_TOLERANCE in tolerance_summary and tolerance_summary[DEFAULT_TOLERANCE]['resonances']:
        best_overall = min(tolerance_summary[DEFAULT_TOLERANCE]['resonances'], key=lambda x: x[4])  # Por erro relativo
        planck_multiple = 1e34 * PLANCK_CONSTANT
        print(f"\nüíé MELHOR RESSON√ÇNCIA PLANCK (Toler√¢ncia: {DEFAULT_TOLERANCE}):")
        print(f"   Zero #{best_overall[0]:,} ‚Üí Œ≥ = {best_overall[1]:.15f}")
        print(f"   Œ≥ mod (10¬≥‚Å¥h) = {best_overall[2]:.15e}")
        print(f"   Erro relativo: {best_overall[4]:.15e} ({best_overall[4]*100:.12f}%)")
        print(f"   Fator: Œ≥ = {best_overall[1]/planck_multiple:.6f} √ó (10¬≥‚Å¥h)")
        print(f"   Equival√™ncia qu√¢ntica: Œ≥ ‚âà {best_overall[1]/(1e34*PLANCK_CONSTANT):.3e} √ó 10¬≥‚Å¥h")
    
    if DEFAULT_TOLERANCE in tolerance_summary and tolerance_summary[DEFAULT_TOLERANCE]['stats']:
        stats = tolerance_summary[DEFAULT_TOLERANCE]['stats']
        print(f"\nüìà TESTES ESTAT√çSTICOS PLANCK (Toler√¢ncia: {DEFAULT_TOLERANCE}):")
        if 'chi2_test' in stats:
            chi2 = stats['chi2_test']
            print(f"   Qui-quadrado: œá¬≤ = {chi2['statistic']:.3f}, p = {chi2['p_value']:.6f}, Significativo: {'Sim' if chi2['significant'] else 'N√£o'}")
        if 'binomial_test' in stats:
            binom = stats['binomial_test']
            print(f"   Binomial: p = {binom['p_value']:.6f}, Significativo: {'Sim' if binom['significant'] else 'N√£o'}")
    
    return tolerance_summary, comparative_results, best_overall

def generate_comprehensive_report(zeros, session_results, final_batch):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = os.path.join(RESULTS_DIR, f"Relatorio_Planck_{timestamp}.txt")
    final_tolerance_analysis, final_comparative, final_best = analyze_batch_enhanced(zeros, final_batch)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("ZVT PLANCK RESONANCE HUNTER - RELAT√ìRIO COMPREENSIVO\n")
        f.write("="*80 + "\n\n")
        f.write(f"Data: {datetime.now().isoformat()}\n")
        f.write(f"Vers√£o: Planck Hunter v1.0\n")
        f.write(f"Lote Final: #{final_batch}\n")
        f.write(f"Zeros Analisados: {len(zeros):,}\n")
        f.write(f"Arquivo de Origem: {ZEROS_FILE}\n\n")
        f.write("CONFIGURA√á√ÉO:\n")
        f.write(f"Constante de Planck (h): {PLANCK_CONSTANT:.15e} J¬∑s\n")
        f.write(f"Constante de Planck Reduzida (‚Ñè): {PLANCK_REDUCED:.15e} J¬∑s\n")
        f.write(f"Comprimento de Planck: {L_PLANCK:.15e} m\n")
        f.write(f"Tempo de Planck: {T_PLANCK:.15e} s\n")
        f.write(f"Massa de Planck: {M_PLANCK:.15e} kg\n")
        f.write(f"Energia de Planck: {E_PLANCK:.15e} J\n")
        f.write(f"Frequ√™ncia de Planck: {F_PLANCK:.15e} Hz\n")
        f.write(f"Toler√¢ncias: {TOLERANCE_LEVELS}\n")
        f.write(f"Toler√¢ncia Padr√£o: {DEFAULT_TOLERANCE}\n")
        f.write(f"Precis√£o: {mp.dps} casas decimais\n\n")
        f.write("AN√ÅLISE MULTI-TOLER√ÇNCIA (PLANCK h):\n")
        f.write("| Toler√¢ncia | Resson√¢ncias | Taxa (%) | Melhor Qualidade | Signific√¢ncia |\n")
        f.write("|------------|--------------|----------|------------------|---------------|\n")
        for tolerance in TOLERANCE_LEVELS:
            if tolerance in final_tolerance_analysis:
                data = final_tolerance_analysis[tolerance]
                best_quality = "N/A" if data['best_quality'] is None else f"{data['best_quality']:.3e}"
                significance = "N/A" if data['significance'] == 0 else f"{data['significance']:8.2f}"
                f.write(f"| {tolerance:8.0e} | {data['count']:10d} | {data['rate']:8.3f} | {best_quality:>11s} | {significance:>8s}x |\n")
        
        f.write(f"\nCOMPARA√á√ÉO DE CONSTANTES PLANCK (Toler√¢ncia: {DEFAULT_TOLERANCE}):\n")
        f.write("| Constante     | Valor              | Resson√¢ncias | Taxa (%) | Signific√¢ncia |\n")
        f.write("|---------------|--------------------|--------------|----------|---------------|\n")
        for const_name, results in final_comparative.items():
            value_str = f"{results['constant_value']:.6e}"
            sig_factor = results['stats']['basic_stats']['significance_factor'] if results['stats'] else 0
            f.write(f"| {const_name:13s} | {value_str:18s} | {results['resonance_count']:10d} | {results['resonance_rate']:8.3f} | {sig_factor:8.2f}x |\n")
        
        if final_best:
            f.write(f"\nMELHOR RESSON√ÇNCIA PLANCK:\n")
            f.write(f"√çndice do Zero: #{final_best[0]:,}\n")
            f.write(f"Valor Gamma: {final_best[1]:.20f}\n")
            f.write(f"Qualidade Absoluta: {final_best[2]:.20e}\n")
            f.write(f"Qualidade Relativa: {final_best[4]:.20e}\n")
            f.write(f"Erro Relativo: {final_best[4]*100:.12f}%\n")
            planck_multiple = 1e34 * PLANCK_CONSTANT
            f.write(f"Fator de Escala (Œ≥/(10¬≥‚Å¥h)): {final_best[1]/planck_multiple:.6e}\n")
            f.write(f"Rela√ß√£o Qu√¢ntica: Œ≥ = {final_best[1]/planck_multiple:.3e} √ó 10¬≥‚Å¥h\n\n")
        else:
            f.write(f"\nNENHUMA RESSON√ÇNCIA PLANCK ENCONTRADA nas toler√¢ncias testadas.\n\n")
        
        if DEFAULT_TOLERANCE in final_tolerance_analysis and final_tolerance_analysis[DEFAULT_TOLERANCE]['stats']:
            stats = final_tolerance_analysis[DEFAULT_TOLERANCE]['stats']
            f.write("RESUMO ESTAT√çSTICO:\n")
            basic = stats['basic_stats']
            f.write(f"  Zeros Totais: {basic['total_zeros']:,}\n")
            f.write(f"  Zeros Ressonantes: {basic['resonant_count']:,}\n")
            f.write(f"  Esperado por Acaso: {basic['expected_random']:.1f}\n")
            f.write(f"  Taxa de Resson√¢ncia: {basic['resonance_rate']*100:.6f}%\n")
            f.write(f"  Signific√¢ncia: {basic['significance_factor']:.3f}x\n")
            if 'chi2_test' in stats:
                f.write(f"  Qui-quadrado: œá¬≤ = {stats['chi2_test']['statistic']:.3f}, p = {stats['chi2_test']['p_value']:.6f}\n")
            if 'binomial_test' in stats:
                f.write(f"  Binomial: p = {stats['binomial_test']['p_value']:.6f}\n")
        
        f.write("\nIMPLICA√á√ïES QU√ÇNTICAS:\n")
        f.write("1. Investigar conex√µes entre zeros de Riemann e quantiza√ß√£o\n")
        f.write("2. Analisar rela√ß√µes com unidades fundamentais de Planck\n")
        f.write("3. Considerar implica√ß√µes para teoria qu√¢ntica de campos\n")
        f.write("4. Explorar conex√µes com estrutura do espa√ßo-tempo qu√¢ntico\n")
        f.write("="*80 + "\n")
    
    print(f"üìä Relat√≥rio Planck salvo: {report_file}")
    return report_file

def infinite_hunter_planck():
    global shutdown_requested
    print(f"üöÄ ZVT PLANCK RESONANCE HUNTER")
    print(f"h = {PLANCK_CONSTANT:.12e} J¬∑s")
    print(f"‚Ñè = {PLANCK_REDUCED:.12e} J¬∑s")
    print(f"Arquivo: {ZEROS_FILE}")
    print(f"Toler√¢ncias: {TOLERANCE_LEVELS}")
    print("üõë Ctrl+C para parar")
    print("=" * 80)
    
    all_zeros = load_enhanced_cache()
    current_count = len(all_zeros)
    if current_count == 0:
        print("‚ùå Nenhum zero carregado. Verifique o arquivo.")
        return [], [], None
    
    print(f"üìä Zeros dispon√≠veis: {current_count:,}")
    session_results = []
    best_overall = None
    batch_num = 1
    
    for i in range(0, current_count, INCREMENT):
        if shutdown_requested:
            break
        batch_start = i
        batch_end = min(i + INCREMENT, current_count)
        batch = all_zeros[batch_start:batch_end]
        print(f"\nüî¨ LOTE #{batch_num}: Zeros {batch_start:,} a {batch_end:,}")
        start_time = time.time()
        tolerance_analysis, comparative_analysis, batch_best = analyze_batch_enhanced(batch, batch_num)
        if batch_best and (not best_overall or batch_best[4] < best_overall[4]):  # Comparar por erro relativo
            best_overall = batch_best
            print(f"    üéØ NOVO MELHOR GLOBAL PLANCK!")
            print(f"    Zero #{best_overall[0]:,} ‚Üí Œ≥ mod (10¬≥‚Å¥h) = {best_overall[2]:.15e}")
        session_results.append({
            'batch': batch_num,
            'timestamp': datetime.now().isoformat(),
            'zeros_analyzed': batch_end,
            'batch_time': time.time() - start_time,
            'tolerance_analysis': tolerance_analysis,
            'comparative_analysis': comparative_analysis,
            'best_resonance': batch_best
        })
        batch_num += 1
    
    print(f"\nüìä Gerando relat√≥rio final Planck...")
    generate_comprehensive_report(all_zeros, session_results, batch_num-1)
    return all_zeros, session_results, best_overall

def main():
    """Fun√ß√£o principal"""
    global shutdown_requested
    print("üåü Iniciando ZVT Planck Resonance Hunter")
    
    try:
        zeros, results, best = infinite_hunter_planck()
        
        if zeros and len(zeros) > 0:
            print(f"\nüéØ An√°lise Planck Conclu√≠da!")
            print(f"üìÅ Resultados em: {RESULTS_DIR}/")
            print(f"üíæ Cache: {CACHE_FILE}")
            print(f"üìä Estat√≠sticas: {STATS_FILE}")
            
            if best:
                print(f"üèÜ Melhor resson√¢ncia: Zero #{best[0]:,} com qualidade relativa {best[4]:.3e}")
                print(f"üî¨ Fator Planck: Œ≥ = {best[1]/(1e34*PLANCK_CONSTANT):.3e} √ó 10¬≥‚Å¥h")
            else:
                print(f"üìä Nenhuma resson√¢ncia Planck excepcional encontrada")
                print(f"ü§î Zeros de Riemann podem ser independentes da constante de Planck")
                
    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è An√°lise interrompida. Progresso salvo.")
        
    except Exception as e:
        print(f"\n‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        print(f"\nüî¨ Sess√£o Planck conclu√≠da!")

if __name__ == "__main__":
    shutdown_requested = False
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    main()
